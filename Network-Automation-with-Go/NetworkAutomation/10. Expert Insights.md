# Expert Insights

As we’re getting closer to the end of the book, we want to do something special. Instead of a more traditional final chapter that reiterates the main points and tries to look into the future, we have done something different and, hopefully, more entertaining for you.

We reached out to several people who have real-world hands-on experience with network automation and/or are using Go for network-related tasks and activities so that they could share their perspectives with us.

We hope that their thoughts, lessons learned, ideas, and opinions will provide you with guidance and more food for thought about the role and importance of automation in the networking industry and reinforce the point that Go is not an esoteric, niche language, but one that is used extensively today for a wide range of network-related use cases.

Without further ado, we present to you the _Expert_ _Insights_ chapter.

Bookmark

# David Barroso

_David is a Principal Engineer working in the intersection between infrastructure and software engineering. Among other things, he is responsible for creating open source projects such as NAPALM, Nornir, and Gornir._

Traditionally, the networking space has been very stable. Most innovations came through standard bodies that took years to be ratified. In addition, vendors promoted certifications with clear and structured learning guides and courses. This meant that network engineers had a clear path to start their careers and become certified experts without having to worry too much about being sidetracked and even without having to bother to figure out what came next for them; someone else had already decided that.

However, the year is 2022 and our everyday vocabulary has gone from acronyms such as MPLS-over-GRE-over-IPSec to others such as IaC, CI, PR, and DevSecOps. Our vendor-driven, slow-changing, cozy life is no more and now we need to keep up with the latest industry buzzwords and the breaking changes in the latest update of our framework/library of choice (luckily, we don’t need to keep up with JavaScript frameworks, for now). But do not despair—take the red pill and be ready to choose your own path.

My advice to keep up with this ever-changing crazy world is as follows: rely less on vendor-driven certifications unless they are a hard requirement for your job. Instead, grab books such as the one you are reading now. Get familiar with the ideas and concepts without worrying too much about the tiny details. Instead of setting up impossible lab scenarios, collaborate with open source projects and learn from the community, the tooling used to develop and maintain the project, the processes, the frameworks, the ideas, and so on. Finally, do not get overwhelmed. People will come up with new buzzwords, libraries, projects, and so on all the time, but if you focus on the ideas, you quickly notice that things are not as earth-shattering as they claim to be and the industry doesn’t move as fast as advertised.

Bookmark

# Stuart Clark

_Stuart is a Senior Developer Advocate Of Community AWS, author for Cisco Press, and a Cisco-Certified DevNet Expert #20220005._

It would be fair to say I would not be where I am now/today without network automation. I was not the first person on the “automate everything” bus, though. I fully admit I was late to the game, or so I felt back in 2014. Since starting in networking in 2008, a number of people have said how they could automate many of their daily tasks, but yet, my ego said my CLI was still better. What held me back? Mostly fear, failure, and not knowing where to begin. It wasn’t until the summer of 2014 that I rolled up my sleeves and said, _I am going to master this now_. Being a network genius, I could easily do this! Nope. This humbled me and I found I could not brute-force learn to code the same way I learned network engineering. For me, a more logical approach was required. This started as just an hour a day in the morning when my brain was fresh and my day of customer network issues and network projects kicked off. I often found I would be stuck in areas for days, too. I could complete labs or copy the examples, but understanding concepts I would often struggle with, so I started making mini projects based on my current day tasks. This often was the same script, but I kept adding and building on this day after day, adding better error handling or validation. Having someone with more experience look over your work and get feedback is great too. After a while, your code has evolved into a work tool that your whole team now uses, and that kick-started many other exciting new workflows. It takes time, but it comes a year or 2 years later.

When anyone asks me about careers, learning new things, or applying for a new role, I always ask: _Where do you want to be in 2 years’ time and 5 years’ time?_ Your skills always need to be sharpened and to do that, you need to hone your skills and learn new things. It is not today we are preparing for, it is our future, and each step of the way requires discipline and consistency. That is where all the magic in you happens. I do not believe we are born with a skill. Sure, we might learn something faster than others. I believe we can be whoever we want to be, and if you have the passion and desire and are willing to put in the work, you can achieve anything.

Good luck in all you do.

Bookmark

# Claudia de Luna

_After graduating from Stanford University, Claudia started working for NASA JPL initially in software development and then moving into enterprise networking. In 2006, she left JPL and worked in several verticals, including biotech and financial. In 2015, while working for one of the largest Cisco VARs, she began automating network workflows. Today, she works for a boutique consulting firm, Enterprise Infrastructure Acceleration, Inc., helping Fortune 100 companies deploy network and security programs at speed._

## Network automation truths... so far...

### 1 – Automation will not replace network engineers

Make no mistake, the discipline of network engineering is not going anywhere. How we interact with devices is amid revolution to be sure, but the knowledge of how a TCP three-way handshake takes place or how a routing protocol works is, and will continue to be, essential. In fact, the depth of this knowledge will likely increase as scripting networking workflows will require an in-depth understanding. I never truly understood Cisco’s **Application Centric Infrastructure** (**ACI**) until I scripted a complete data center ACI fabric build-out.

### 2 – The power of text and revision control

This does not get said often enough (or ever), but text is all-powerful. It is the lowest common denominator as well as the input to rich typesetting output with which to convey a written language (programming or otherwise). While putting together a richly formatted book or a computer script, you can take the simple text and snapshot its evolution over time. In this way, you know the exact nature of every change. This is revision control. Originally developed to track code changes, today, as with network automation, you can put configurations, configuration templates, state, diagrams, documents, and almost anything under revision control. Before you leap into scripting, take a little bit of time to learn a revision control system such as Git and GitHub.

While we are on the topic of text, get a real text editor! Notepad and TextEdit are only handy if you have no other option (and learn `vi`—see _9 – Linux and regular expressions_). Invest the time to get familiar with more advanced text editors such as Sublime or Atom.

### 3 – Just start

Approaching something new and unfamiliar can be daunting. Just start. If you are new to programming, search for resources on basic programming concepts or programming fundamentals. This is an important step if you are _NOT_ familiar with the concepts of variables, scopes, operators, control structures, and namespaces.

Once you have a footing in these concepts, write down a particular problem you want to solve, pick a language, and **dive right in**. For me, it was generating configurations. In fact, for every new programming language I learn, that is the first problem I solve. I’m just working with text and not actual devices, so I can’t get into too much trouble. If there is a small problem at work that you are comfortable tackling, start there. Define the problem clearly, detail the desired outcome, and just start. Jot down the specific steps and tackle each one individually.

Let’s say you want to generate configuration commands for configuring the same VLAN on 10 devices and, just to keep it simple, output the necessary commands you need to run on each device to the screen. Your first script could be as simple as taking a list of devices and printing out to the screen the following configuration:

```markup
!Switch01 vlan 10
name Vlan10_on_Switch01
```

Once you have that, you will want to save the output to a text file. After that, you will want a file for each switch. After that, you will start to customize each switch. You get the idea. Every enhancement will teach you something new. Every new feature will expand your experience.

### 4 – Embrace the landscape

Doubly daunting is the fact that you are trying to learn something new, but there is so much to learn! See _3 – J__ust start_. The experience you get from learning something and then abandoning it for something better is invaluable. Being able to articulate why you prefer one solution over another or why you are recommending a particular approach will immediately set you apart and will instantly generate credibility. This makes you a true engineer.

I believe there is as much value in trying something and abandoning it as there is in trying something and adopting it. This process makes you credible. It moves you from someone who says, _You should use X. Why? Uh.. because ..._ to the person who says, _For what you are trying to do, you should use X because X has these features or is easier to support in your environment or ..._. Cultivate the ability to articulate why you are recommending something, along with why you are not recommending something.

That experience, that _credibleness_, has served me well as a female in a largely male-dominated industry. I’ve shown up for a job or a meeting with males and had the client speak only to my male counterparts. That credibility and these fact-based recommendations always win the day. They may start out talking only to my male teammates, but they end up speaking with me. That will always hold true and not just for gender.

### 5 – Share and package

It’s tempting to code for yourself but think about the impact you can have if you empower your team. To that end, as you write your scripts, think about how you would write them if you had to share them. Think about teaching a teammate who has zero programming or even CLI experience to execute one of your scripts. This will get you thinking about how to package your script. There are many options, including turning your script into a Windows executable if that is your _audience,_ or front-ending your script by a GUI or web page if your team leverages different operating systems.

### 6 – No limits

In network automation, it’s very easy to focus solely on automation for infrastructure. Don’t do that! Think about an environment where your final documentation was automatically generated by the configurations. Have to do lots of change control tickets that are often similar? Think about an environment where your change control information was generated by a script. And the closeout is also generated by a script. Want to add a diagram to your documentation? Think about a world where your diagram was autogenerated from your new topology. Have to interface with another team and share information with them? How appreciative would they be if you shared just the information that they needed in a consistent format rather than making them slog through an email thread or an exasperating Excel spreadsheet?

### 7 – Understand data structures

How you put your data together has far-reaching implications. Get comfortable with complex data structures. By data structures, I mean lists and dictionaries and every combination thereof. Ask yourself: will my code be clearer if I iterate over a list of dictionaries or if I pick data from a set of keys? Get comfortable extracting the data you need when these data structures are highly nested. For more on this topic, see my post _Decomposing Data Structures_ (in the _Further_ _reading_ section).

### 8 – Learn about and use APIs

Many modern network devices now offer APIs. These APIs will generally return the answers to queries in structured data (See _7 – Understand data structures_). If you don’t have to log in to a switch, pull a configuration, or show a command in semi-formatted text and then parse that text, don’t! Use an API. In addition to APIs offered by infrastructure appliances and network devices, there is a wealth of data available, often with open and free APIs.

Need to look up the vendor OUI of a MAC address? There is a public and free API for that. Need to look up the physical location of an IP address? There is a public and free API for that. Enrich your data, reports, and information with APIs.

### 9 – Linux and regular expressions

I can’t stress this enough. A background in Unix is invaluable. Many infrastructure devices start out with a Unix or Linux base. Having this background will further distinguish you from the run-of-the-mill network engineer. Part of having some Linux knowledge should include knowledge of regular expressions. Because network automation invariably requires some parsing, having a familiarity with regular expressions will help you do your own parsing and will help you work with other parsing modules. The more sophisticated text editors understand regular expressions to facilitate your searches.

### 10 – Wander and explore

Finally, set aside time to explore. I try to set aside at least two Sunday mornings a month where I take something I heard about or read about or saw and start exploring, or I take a problem and research solutions. No destination in mind, I just see where it takes me. Half the time, I start with one thing and wind up basically on another planet. I’m going to take an Udemy course on MongoDB and I wind up trying to create the best regular expression I can for matching an IP address. _I’m not hung up on this completion thing_ (at least on Sundays).

Bookmark

# Alexis de Talhouët

_Alexis de Talhouët is an avid network automation expert always trying to lessen network complexity by getting involved in open source communities; he was mainly involved with OpenDaylight (ODL) and Open Network Automation Platform (ONAP), both hosted by The Linux Foundation, where he held Technical Steering Committee membership._

I initially started my career as a Java developer, with a massive passion for networking. At first, it felt very weird to build systems automating networks without really understanding them. But throughout the years, I learned to be sufficiently proficient in networking to properly build automation platforms around it. Such knowledge can be acquired either by building labs, following workshops, or, for the luckiest ones, spending some time in a network operation center.

Something that struck me the most, and is still true, is how much the path to network automation can be different if you come from a software developer versus a network engineering background. Both have their own acronyms, processes, standards, and so on, and yet, with the rise of cloud-native, Infra as Code, Network as Code, GitOps, and so on, we saw both worlds adopting similar concepts, methodologies, and tooling to do the initial provisioning and operate the entire life cycle of what was automated. So, at a high level, the _how_ to perform the automation became fairly common, whereas the _what_ still remains fairly domain-specific. When embarking on such a journey, we should really take advantage of this ecosystem to accelerate our automation strategies.

In my opinion, the basis of network automation is the configuration to apply a (golden) template of that configuration with well-defined (typed) parameters, and the protocol used to apply that configuration. Another very important element required for service assurance is the notion of telemetry, to retrieve the running state and get updates on state changes and state.

With my developer hat on, what matters most is the API/contract exposed by the network equipment/network function; these are commonly represented by the device YANG models. The main issue is, given the network is non-homogeneous, each vendor has its own models, and exposes more or less its functionalities. Even though there is a lot of effort being put into standardizing the configuration and monitoring of network equipment (OpenConfig, OpenROADM, and IETF), this is certainly not fully adopted, and thus still requires a lot of _cookie-cutter_ handling.

Network automation strategies must account for this and accordingly design their platform to accept any type of network automation techniques. Of course, the more the said platform attempts to abstract that non-homogeneous environment, the more maintenance there is, as the shim layer that will convert from the device’s native API to that higher-level business API will have to keep up with the pace of device upgrade and device model change.

This put forward the following design decision: should you strive to have one abstraction layer for your entire network and maintain a shim layer that talks southbound to devices?

If yes, you’d better be armed with a team of developers to build and maintain that abstraction.

If not, I suggest solving the issue by letting the network engineers build that golden template for each network service and have a platform to load, version, and interact with them. And that interaction might be a shell script, a Python snippet, a Go program, an Ansible playbook, and so on: whatever might work for that specific team, as long as the said platform exposes a REST API with the ability to execute it. That way, network teams are empowered to automate by exposing the API and can stop worrying about the platform. The onus of keeping these golden templates and scriptlets becomes theirs.

Another important aspect is having an orchestration engine enabling the definition of a workflow consuming these domain-specific APIs. With maturity and governance, enforcing pre-check and post-check tasks should become a must-have in these workflows. Also, always consider how to roll back if the post-check isn’t successful. Applying and rolling back configuration can be tricky when doing network-wide transactions; consider building helper functions to increase reusability.

These orchestration engines can either be distributed or centralized, but often there will be an end-to-end service orchestration that will consume these exposed domain-specific workflows.

Finally, one of the key components to keep in mind is the inventory of the network elements/functions. As soon as a workflow does something, it is important to have and keep the inventory up to date so that service assurance workflows can properly act upon the active and available state of the network.

Given most of the network automation is currently done either through NETCONF or gNxI southbound protocols, YANG has become the de facto model standard to define and express device configuration, and the tooling around YANG is mature enough to rely on XML/JSON for the golden templates. Rendering these templates is also something easily doable, regardless of the technology used, even if enforcing YANG-defined types. Considering all of this, when starting a network automation journey, I wouldn’t advocate for a specific programming/scripting language, but rather let each team manage that for themselves. But I would definitely advocate for standardizing as much as possible the southbound protocol and interaction. As the journey matures, and you feel that, as an organization, you have a better handle on a specific technology, then you can build more helpers and start putting forward some company-wide practice for automation.

As the network automation domain evolves, infrastructure provisioning is also evolving. With the rise of Kubernetes, the latest trend is to extend the Kubernetes API to provide **Custom Resource Definition** (**CRD**) abstracting hardware and software configuration, and supporting their entire lifecycle through the use of an Operator. An Operator exposes the CRD as a K8S native API and contains the logic for managing the end-to-end lifecycle of a CRD instance. This is shifting the responsibility of operation to the Operator provider and is fostering intent-driven automation. As network equipment vendors adopt this concept, network automation will become even closer to application lifecycle management. And with this trend, one of the main programming languages being put forward is Go.

One project to look at is Nephio, the latest Linux Foundation networking initiative aiming at providing network controllers using Kubernetes API extensions.

Happy coding!

Bookmark

# John Doak

_John Doak is a Principal Software Engineer Manager at Microsoft, an ex-Google Network Systems Engineer (SRE), and an ex-LucasArts/Lucasfilm Network Engineer._

I cut my teeth in networking at LucasArts after I asked the Director of IT what my next career step was. He made me a network engineer on the spot and said to go buy a Cisco book and configure a router for a new T1 we just got. There is nothing quite like staring at a box in a closet, hoping that the Cisco book you have placed on top of your head will give you knowledge via osmosis. I spent the next several years there automating my way out of doing work (portals that reset network MAC security parameters, moved ports to new VLANs, auto-balanced inbound BGP traffic using route maps, and so on).

I moved from there to Google, where I spent the bulk of my time automating the vendor backbone known as **Backend Backbone** (**B2**). I wrote the first autonomous services that programmed the various routers. Then, I built the first workflow orchestration system for the network with some very talented software engineers (Sridhar Srinivasan, Benjamin Helsley, and Wencheng Lu), and then I went on to build the next version (because you never get it right the first time). The biggest change between the first and second was moving from Python to Go. We were able to decrease our bugs, increase the number of workflows by 10x, and made it possible to refactor the code without breaking everything. I spent the next few years migrating all of NetOps onto Go from Python and building automations that configured the network on a daily basis (BGP mesh deployments, LSP metrics, SRLG configuration deployments, edge router turn-ups, BGP-LU updates, ISIS metrics, LSP optimizations, and so on). One of the keys for making that scalable was another service I wrote that allows sending an RPC that could configure any vendor router we supported for a change (such as configuring a BGP peer).

Now, I work at Microsoft where I no longer am working in networking, but write Go SDKs and manage a software group that deploys software to validate data, supply gating controls, audit data sources, and so on. This includes running Kubernetes clusters, deploying software, and building tools to run these systems.

Finally, I’m the author of the book _Go_ _For DevOps_.

If I could give one piece of advice for network automation: use a centralized workflow orchestration system. The benefits of a centralized workflow system to allow visibility into what is happening in your network, allow emergency controls, and provide policy enforcement have been proven time and time again.

So, what do I mean by centralized workflow enforcement? You want an RPC service that exists and has a set of actions that the service can do. Your tools submit an RPC describing the set of actions and monitor the running of that from the server.

This means all executions are running out of the same place. You can then build emergency tools to stop problem network executions in case there are issues (or simply pause them). You can enforce concurrency limits on how many network devices can be touched within a time period. You can provide network health checks that have to run before an automation can run.

Centralization is key to controlling the automation on your network. When you’re in a small group, it is easy to know what is going on. When your group grows much beyond five people, this starts to become impossible.

Two of the largest outages I witnessed at Google were due to engineers running scripts on their desktops that mutated the network while they were working outside their time zone. Backtracking to who/what was causing the issue required scanning TACACS logs to find the culprits. And if the scripts had been making ongoing changes, no one could have stopped it without tracking down someone in security to disable their credentials. That precious time might mean that your entire network is down.

If you’d like to look at a basic workflow system that could be used for network actions, see my _Designing for Chaos_ chapter in the _Go For_ _DevOps_ book.

The packets must flow!

Bookmark

# Roman Dodin

_Roman is a Network Automation Engineer with a product management hat signed by Nokia. Besides his professional affiliation, he is a renowned open source leader, maintainer, and contributor in the network automation landscape. You might recognize him as the current maintainer of the Containerlab project, which you will come across while working on the practical exercises provided within this book._

I assume you are already into Go, and you want to see how Go can apply to the network automation problem space, or you’re curious to know _why Go for network automation_. Allow me to share why I once switched to Go, what were the main drivers for that move, and why I think it is a perfect time for network engineers to start looking at Go.

Before delving into Go, I used Python for all things network automation; no big surprises here. For the past couple of decades, the _usual_ network automation workflow revolved around crafting/templating CLI commands, sending them over SSH/Telnet to the network element’s CLI process, parsing the replies, and processing them. Back then, you were lucky to have any kind of vendor-provided REST API. Hence, most automation projects were using screen scraping libraries with all the pains of dealing with unstructured data in an ad hoc way.

Meanwhile, in the IT realm, the proliferation of containerization, micro-segmentation, and Infra-as-Code paradigms was coupled with the Go language mounting solid ground. The simplicity of the language syntax, coupled with a rich standard library, compiled nature, first-class concurrency, and decent performance, made Go win lots of developers’ hearts. In no time, we witnessed a new ecosystem—**Cloud Native Computing Foundation** (**CNCF**)—emerge with a new set of requirements on how applications get deployed, run, and interface with one another. Consequently, the community revisited the networking layer to comply with the new way of running applications in an API-first, cloud-native setting.

With time, the waves made in the sea of IT reached the networking island. Nowadays, any decent network OS carries on top a set of management APIs with structured and modeled data for anyone to consume. The modern automation workflow assumes leveraging those APIs solely in a concurrent, performant, and cloud-native way. And you guessed it right: being able to write concurrent, performant, easily deployable applications leveraging the sheer set of cloud-native tools and libraries is what Go offers to network automation engineers out of the box.

Even with the inertia levels we have in networking, the ecosystem of network-focused projects is growing fast. As you will see for yourself, getting through the chapters of this book, typical network-related libraries have been created for Go already.

Another critical player in the network automation/management field is the OpenConfig consortium. Spearheaded by Google with the participation of network operators, OpenConfig conceived many network automation projects that gravitate toward Go—`goyang`, `ygot`, `kne`, `ondatra`, and `featureprofiles`. Those who want to get a grasp of what these projects have to offer will have to get a hold of Go. As it often happens, the tools that we will consider a commodity in the future are being shaped by hyper-scalers today.

In summary, if your network automation activities have any of the following properties, you might consider Go as a tool for the job:

-   Require being performant at scale.
-   Have a strong use case for concurrent execution.
-   Use generated data classes off of YANG models.
-   Leverage Kubernetes control plane.
-   Integrate with CNCF tools and projects.
-   Make use of OpenConfig projects.

Echoing others, Go is not an ultimate answer or a replacement for Python/Java/and so on. It is, though, a programming language with a solid set of strong points, a large community, and a flourishing ecosystem. In my opinion, it has a bright future in the network automation domain, and this book should be an excellent aid for those who want to see the practical aspects of using Go for network automation today.

Bookmark

# David Gee

_David Gee is a Director of Product Management at Juniper Networks. He blogs at dave.dev, previously ipengineer.net. He is the creator of the JUNOS Terraform Automation Framework (JTAF), among other things. Twitter: @davedotdev_

If you’ve built knowledge in the network space, chances are you’ve purchased and inhaled knowledge from _Cisco Press_ books. These books, for the most part, are well structured and provide knowledge that opens up like a flower. For those looking to build automation knowledge, good sources of knowledge that are multi-vendor-friendly are hard to come by. The industry itself is fairly immature, and network engineers developing software skills vertically in the networking silo tend to make very questionable decisions. This isn’t the fault of the network automation engineer but is due to a lack of discipline that’s present in the industry. In plain-old networking, if you configure BGP badly, a session might not come up. If you accidentally leak prefixes, then someone will correct your knowledge pretty quickly. The next time you configure BGP, you probably won’t make that mistake again!

Software discipline in the networking space is sorely needed, and many organizations are still in their nascent networking automation phase. Bad experiences in this phase normally are catastrophic for confidence levels and either confirm that it’s too hard or light the runway for a great take-off. There are lots of people going to bootcamps still, and thanks to Udemy, Pluralsight, and a raft of other learning platforms, it’s easier today than ever to get into software. This is a contentious topic and I want to be careful here, but software isn’t all just throwing lines of code at something until it works on a knife edge. It’s a discipline, a mindset, and requires rigor.

## My journey toward a decade of Go

Go is a great language, and for many, it’s a primary programming language as well as a tooling language. Go provides a “belts and braces approach” in which even the compiler nags you to do the right thing. Sure, you could write sloppy code, but the whole Go ecosystem is wired to help you not do that. Most of the IDEs on the market have great Go tooling and will further lint and format your code, kicking you into being a better developer. Mat Ryer of Grafana Labs and the “Go Time” podcast once said: "_Because of the Go tools, I can read other people’s code and it feels familiar as if I’d written it."_ That’s down to how the Go community has baked best practices into the toolchain. You get that for free.

For amusement, but also to make a point, I’m going to share a moment from my past career. I wrote C back in the day (C99) and wrote it on Microsoft Windows Notepad, linked it, and compiled it with individual tools into a binary, which then needed burning onto EPROMs for an embedded system. I managed thousands of lines of plain text, without so much as a hint of what was going to work at the time of writing. Test rigs helped, but the real world is always the truth. One day, I was called to an industrial unit where one of my systems had blown the lid off a water reservoir tank. In the moment and under pressure, I managed to find a bug because I’d written down the algorithm and left key comments in the code so I could follow under stress. Great tools and a solid engineering approach to writing code will save you from being fired or, even worse, being sued. If it was all spaghetti code (some of it was—I’m no hero), I’d have probably been imprisoned. Since then, we have great IDEs at our fingertips, and Go takes the best bits of C (in my opinion) and gives you a development journey that I’ve not found anywhere else. Ahead of even risking a production run, the compiler can tell me about race conditions, pointer problems, and a whole raft of things that I’ve been waiting decades for.

Beyond the IDE, compiler, and Go toolchain, Go lends itself to writing clear, readable, and maintainable code because of things such as error handling and desirable repetition. Avoiding magic is a key tenet, and you should be able to import a package and initiate it deterministically in your own code because of the discipline within the Go community.

Go offers so many out-of-the-box features, newcomers tend to get Go punch drunk. It’s normal to see goroutines appearing everywhere and channels being used in situations where they’re just not needed. Bill Kennedy of Ardan Labs has some great material on this, and if you think you need a goroutine, the chances are you probably do not. It’s worth profiling your code with `pprof` before building things that you don’t need and doing some benchmarks through Go’s testing capabilities. Go in its simplest form will probably outperform your use case, and deciding to keep your design architecturally simple in the early days will prevent complex headaches in the future.

## Go’s type system

Go’s type system can be strict to work with, but it provides the rigor and structure that you absolutely need. Network operating systems are normally based on structured data and things such as NETCONF engines have API schemas that are modeled from YANG. By consuming the **domain-specific language** (**DSL**) that defines the schema of the NOS data, you can generate one-to-one mappings against your Go code. The result is that by ingesting YANG and GPB, you gain predictable and reliable data structures, which are an important part of the API contract for interacting with a NOS. As network telemetry trends grow, a clear winner is working with GPB and gRPC. Good news! You can take the `.proto` files and get programmatic contract alignment for free when building client code. The same principle works for XML as it does for gRPC and GPB. There are many tools available for building data structures, and some IDEs have the capability to go from JSON to structs. Use the tools where they are available, but never dismiss the opportunity for entropy and drift. Version control is important for this very reason alone. As a final note on data encoding and schemas, XML is rich and programmatically powerful. JSON might be a cool kid thing, but XML is great to work with for generating configurations for platforms such as Junos. If you are comfortable with XML, working with NETCONF is one small stone’s throw away. When building types with Go, encoding XML is just as easy as JSON. Here’s an example of that:

```markup
package main
import (
     "encoding/json"
     "encoding/xml"
     "fmt"
)
type DataEncodingExample struct {
     /*
           Example payload
           {
                "_key": "blah",
                "_value": "42",
                "_type": "string",
           },
     */
     Key   string `json:"_key",xml:"_key"`
     Value string `json:"_value",xml:"_value"`
     VType string `json:"_type",xml:"_type"`
}
func main() {
     dataInput := DataEncodingExample{
           Key:   "blah",
           Value: "42",
           VType: "string",
     }
     jsonEncoded, _ := json.Marshal(dataInput)
     xmlEncoded, _ := xml.Marshal(dataInput)
     // This is example code. What errors? :)
     fmt.Println("JSON Encoded: ", string(jsonEncoded))
     fmt.Println("XML Encoded: ", string(xmlEncoded))
}
```

The output is as follows:

```markup
JSON Encoded:  {"_key":"blah","_value":"42","_type":"string"}
XML Encoded:  <DataEncodingExample><Key>blah</Key><Value>42</Value><VType>string</VType></DataEncodingExample>
```

## A note on version control

On to version control, which is not only important for your own code but also important for Go’s package management system. There have been more than 10 package management attempts from the core Go team, but as of version `1.13`, the Go module system feels like they finally got it right. If you’re unfamiliar with `go mod` and its use, it’s worth investing the time. Being able to deterministically rebuild a Go program with the correct package is of prime importance, and it’s worth understanding how you can use semantic versioning and the `go mod` system to sturdy up your development habits. There are famous stories in the DevOps and SRE space about one patch version being off and code being entirely unpredictable. As great as those stories are when telling them at meet-ups, they aren’t fun in the moment and can be avoided by locking your code to use specific versions and trusting that in CI/CD pipelines or build systems, your code will be re-composed the same way you composed it in development.

## Growing your code

I’m thankful to have been an electronics engineer before I went into networking and learned assembly language and C before even so much as touching a CLI. I found it odd that I could make more money typing commands into a serial port than building a system with a serial port. Roll the calendar forward two decades (yikes), and many of my old habits are still in existence. If I begin to write a new tool or software service, I start by building out the kernel of the idea without implementation. This vehicle enables experimentation and learning about the problem space without lots of tedious code changes in the early phases of exploration. The algorithm kind of grows itself, and over time, I’ll embed links to useful API code or comments I’ve found on forums and blogs, and so on:

```markup
package main
import (
     "context"
     "fmt"
     uuid2 "github.com/google/uuid"
     "github.com/sethvargo/go-envconfig"
     log "github.com/sirupsen/logrus"
)
const _VERSION = "0.0.1"
/*
This code logs into the auth service for X and then updates the remote status with the local status measurement.
It is triggered when the remote state is changed.
Each invocation generates a UUID which can be used by the ops team.
*/
type Config struct {
     APIUser string `env:"PROG1_API_USER_ID"`
     APIKey  string `env:"PROG1_API_USER_ID"`
}
// GetToken retrieves a JWT from the external auth service
func (c *Config) GetToken(URL, uuid string) (string, error) {
     // Initiate thing
     log.Info(fmt.Sprintf("system: updater, uuid: %v,
      message: logging into device with key %v\n", uuid,
      c.APIUser))
     // ImagineDevOps  this is implemented!
     return "JWT 42.42.42", nil
}
func main() {
     // Set log level, normally this would be from config
     log.SetLevel(log.DebugLevel)
     // Get UUID for this instantiation
     uuid := uuid2.New().String()
     // Show the world what we are
     log.Info(fmt.Sprintf("system: updater, uuid: %v,
      version: %v, maintainer: davedotdev\n", uuid,
      _VERSION))
     ctx := context.Background()
     // Get the config from env vars
     var c Config
     if err := envconfig.Process(ctx, &c); err != nil {
           log.Fatal(err)
     }
     // GetToken will get a JWT from the thing upstream
     token, err := c.GetToken(
            "https://example.com/api/v1/auth", uuid)
     if err != nil {
           log.Fatal(err)
     }
      log.Debug(fmt.Sprintf(
      "TODO: Got token from external provider: %v\n",
      token))
     log.Debug("TODO: Got the local state")
      log.Debug(
      "TODO: Logged in to remote service with token and updated the state")
     log.Debug(
      "TODO: Update success: ID from remote update is: 42")
     log.Debug("TODO: Our work here is done.")
}
```

The output is as follows:

```markup
go build
./main
INFO[0000] system: updater, uuid: 6cb60c9b-<snip>, version: 0.0.1, maintainer: davedotdev 
INFO[0000] system: updater, uuid: 6cb60c9b-<snip>, message: logging into device with key testuser 
DEBU[0000] TODO: Got token from external provider: JWT 42.42.42 
DEBU[0000] TODO: Got the local state                    
DEBU[0000] TODO: Logged in to remote service with token and updated the state 
DEBU[0000] TODO: Update success: ID from remote update is: 42 
DEBU[0000] TODO: Our work here is done. Exit Go routines cleanly if there are any.
```

A couple of items in the preceding code are worth mentioning. The first mention is on the use of external packages. I tend to standardize on a given project for a logging library and method of dealing with configuration. It makes the code easy to work with and predictable in its nature. Also, great libraries are gifts that keep on giving. Logrus is a great example of that. Want JSON? Not an issue. Want to change the log destination? Easy. Logging is not only important in development, but it’s super important when you release a tool or put a software service into production. It might seem silly to have a UUID system in place for a low-use tool, but if it’s a software service with many invocations per day, you can PayPal me a suitable gift when operations tell you how nice it is to follow what your creation does.

## Comments

The value of comments is an age-old subject for shouty arguments. Be kind to the future version of yourself or any poor soul that has to maintain your code. Comments are worthless if they point out the obvious, and so I write a small variation of comment styles. They say _know your audience_ when you write, and for reading code, the required expertise is a basic understanding of Go, and so you do not need to point out that a string is a string. Here are some pointers on what you could include:

-   **Future hints**: This is when there is a known bottleneck or issue that’s likely to arise at a certain user base or request rate but is not worth solving at the time.
-   **To-do items**: When exploring problem spaces, there’s nothing wrong with leaving mental hooks so that you can relocate your thoughts. They should reduce over time as the algorithm becomes more concrete, so remove them and improve the explanations in larger comment chunks as you work through your to-do list.
-   When things get complex, write the algorithm out. It’s like reading an exec summary in a corporate document. It’s easier to understand what the code is trying to do from a tech memo comment than from reading the code, especially if it’s complex and deals with things such as recursion. Always worth leaving a date too so that readers can reconcile versions against comments.

## Being blindsided

Because writing in Go forces you into good habits, it can also blindside you. Go is massively powerful and packed with features that are quickly turned into invisible guard rails. ImagineDevOps  interacting with an API that’s been written in Python. ImagineDevOps  also that the payload is encoded into a slice with each item being a small map—something simple, like this:

```markup
[
     { 
           "key": "blah", 
           "val": 42
     }
]
```

Immediately, we can see how to marshal and unmarshal, but a common gotcha, especially when interfacing between a strongly typed language and a dynamically typed language, is poor data type management discipline. The following example will trigger an error in Go when you attempt to marshal it because of the type system, but it’s really common to see, unfortunately:

```markup
[
     {
           "key": "blah1",
           "key": 42
     },
     {
           "key": "blah2",
           "val": "42",
     },
]
```

Some software engineers handle these scenarios with TLV-style data encoding (see next), but if you’re stuck with this problem, you can use Go’s `reflection` capabilities to inspect the data and de-serialize it in a customized way for handling within your code. You could use reflection with the preceding code to then instantiate in types such as the following. This approach has saved my bacon more than once and is especially of use in dynamic data scenarios where languages such as Python make it dangerously easy. The user of the underscore is normally a hint that this is a TLV-style data instance and used for inter-process communication:

```markup
/*
     {
           "_key": "blah",
           "_value": "42",
           "_type": "string",
     },
*/
type BadDataManagement struct {
     Key   string `json:"_key"`
     Value string `json:"_value"`
     VType string `json:"_type"`
}
```

Go is a great language, and I implore you to work with standardized interfaces such as NETCONF, REST, and gRPC while making an effort to avoid silver-bullet _network API_\-style packages and middleware. Simple rules such as avoiding magic will pay dividends in the future and, having a memory like a sieve, I try to remember that at all times if nothing else.

Writing this section has been an honor, and I believe this book paves the way for you to develop your own discipline, rigor, and skill for an industry that desperately needs it. Without lightning-rod efforts to provide learning paths, we’ll find the network automation discipline heavily fragmented for years to come, and this book will help immensely with that journey. A huge thank you to the authors for letting me share these thoughts.

Bookmark

# Daniel Hertzberg

_Daniel is a Senior Technical Marketing Engineer at Arista Networks. He’s been working within this field for double-digit years and has always had one foot in the door of networking and one foot in the door of automation/programmability. He writes Go on Visual Studio Code multiple times per week because of his success with network automation, cloud-native technologies, and OpenConfig._

I started off my automation not with network devices but with network overlays and network security with VMware NSX. NSX provides way too many options to click on to break the system. The same way that a network person could make a mistake and fat-finger a switch made it really easy for me to enter the same OSPF router ID within the same network... whoops! This was a REST API built with XML as an encoding and used Python requests to talk to it. At the time, most were using PowerShell to make this work, so even Python in this community was way outside the barriers of normalcy.

Fast forward a few years later—we started to see a lot of usage with vendor APIs. I found Python more or less at home given the amount of “getting started” examples that were out there simply importing the `requests` library and doing the typical RESTful thing—that is, sending a request and getting a response back. I found it pretty simplistic to generally work with all the normal Python objects such as dictionaries, lists, tuples, and so on.

Within every journey, you start to run into scaling problems, and there is no issue with Python if it works for what you are doing. I started getting more involved in cloud-native projects, Kubernetes, and OpenConfig. All things that ended up using Go. I felt the learning curve was a bit steeper than Python because the network community was not as into it as they were into Python. However, the benefits outweighed everything I knew about Python:

-   Typed system
-   Compiled system
-   Concurrency
-   Modules (`go mod` is so great to open it up and see what is being used across the entire project)
-   No white spacing
-   Garbage collection

I could probably add a bit more, but those are generally why I like Go so much. Having early access to this book and seeing the examples, I can see generations of network engineers picking this up rather easily and swapping out Python for Go.

Go overall has helped me tremendously in my career as customers are asking for more and more code written in Go for general networking projects including Kubernetes operators, network automation, and OpenConfig streaming. Best of luck, network gophers!

Bookmark

# Marcus Hines

_Marcus has spent his career focused on network device testing, test framework development, test automation and generally asking why things can’t be done differently. He started his career as a Network Engineer and he now focuses on engineering productivity across his organization. He helps maintain most of the OpenConfig organization’s repositories._

## In a nutshell

I have become a very strong proponent of Go for general development for several key aspects:

-   Ease of use of language-provided tooling
-   Ramp-up speed for engineers joining projects
-   Speed of compilation and multi-platform support
-   Strongly typed language for static analysis with great build-time validations

## Reasoning about automation

-   **Testing and automation are basically the** **same thing.**

Testing and automation can be distilled down to an ordered set of operations and validations to transform an input state and intent into an expected output state.

-   **A stream of bytes is not** **an API.**

SSH and shell scripts that contain vendor-specific details do not lend themselves to a heterogeneous environment.

-   Flexibility on API definition, which focuses on iterative versioning with non-breaking changes.

Go has strong first-class support for gRPC, which is a rich serialization and RPC framework with support for most popular programming languages.

-   Automation should always only have one layer of templates and one layer of configuration. Everything else should be code.
-   One automated test running continuously is worth 1,000 manual tests.
-   Automation systems themselves need to be life - cycled.

The first test developed for the system should be how to install, version, and tear down the system itself in a hermetic, repeatable way.

Once you have that ecosystem, you can unlock the rest of your development team to quickly iterate on development with the trust they are not regressing the infrastructure.

## Background

I have had a very long winding path to come to where I am today.

I started my network automation _scripting_ back in TCL/Expect and Perl. Both of these ecosystems allowed for at least consistent repeated operations; however, everything else was a mess. Python added a robust ecosystem around libraries and version systems to allow for a more hermetic and repeatable world.

The Python code base, though, suffered from a couple of issues, which made it hard to maintain. The testing of the code itself was fairly straightforward. However, because of a lack of typing, we often had to write a lot of type validation into the code and could only find these errors during runtime. Also, the general focus on using mocking to drive up coverage numbers but not extensively testing the public contracts caused fairly brittle tests, which slowed development in the long term. I don’t blame Python specifically for this, but it is very easy to fall into a pattern without the right tooling to enforce good practices.

I was introduced to Go around 2014 on a project and was quickly impressed with its strong typing, built-in tooling, and compilation speed. Before this, I had been working on a C++ test framework for a project. I was constantly frustrated with the complexity of building _flexible_ C++ code; it had become a meta-programming nightmare of templates to generically support all of our use cases. Go fixed most of this by providing interface definitions for our use cases.

Since then, I have written three Go-based test frameworks for different organizations, all with different system needs. The first framework represented some unique challenges for solution testing. It required the ability to be open sourced. It needed to control components written by four different teams developing code in three different languages across two different build ecosystems. The tests themselves had to run on both Linux and Windows test runners. Go allowed us to develop this ecosystem using just standard Go tools for compilation.

The next framework was used for solution testing of a cloud-based Kubernetes ecosystem. We were able to make quick progress given the tooling and library support for k8s based projects. We could leverage infrastructure for cluster bring-up, k8s deployment, operator deployment, and application lifecycle.

The current framework I am involved with is Ondatra (see the _Further reading_ section). This framework is focused on delivering an open source functional-, integration-, and solution-testing framework for network solutions. It is currently used by internal teams in my organization through feature profiles (see the _Further reading_ section) for describing our network device requirements to vendors.

## Ability to impact the industry

One last point I would like to make is the ability of individuals to change the industry.

This industry has long been dominated by vendors and the perception that the IETF will solve your problems. When it comes to automation, vendors are disincentivized to help. Every vendor-specific knob and API that can be created locks an operator further into a vendor solution that translates into **purchase orders** (**POs**) for them.

By starting to shape this industry around software automation and APIs, we are moving a network from an art to computer science. We are on the path to where network devices are nothing more than general-purpose compute with fancy network interface cards. With general APIs that can express intent, such as OpenConfig over gNMI, operators can build a single configuration and telemetry system that can support any number of vendors. With additional operational APIs around bootstrapping, security, software, and file management, operators can uniformly build their infrastructure. This becomes a very consistent testable layer that then can be used to test northbound services and downstream devices separately at the unit test layer. Building a strong layered test strategy gives you confidence and finds breakages much faster in your development cycle.

Don’t wait for others to solve your needs; it won’t happen. If you want something, demand it from the vendors. If they don’t do it, demand it from a standards body. If they don’t do it, take it upon yourself. Don’t assume your idea is a bad one or that others have more understanding of the ecosystem than you do. Get into the open source world and pitch your ideas. The model of software development and collaboration has drastically changed over the last 20 years, let alone just in the last 5 years. Network automation has many opportunities to develop ecosystems that can have a minimal number of transforms between operator intent and state on network devices.

Bookmark

# Sneha Inguva

_Sneha is a Software Engineer at Fastly on the network control and optimization team and a former Network Engineer at DigitalOcean._

My journey to writing networking code began on the internal Kubernetes and observability teams at DigitalOcean, a cloud hosting provider. Before I ever touched a line of network code or configuration logic, I learned that behind a planet-scale company is a multitude of distributed systems consisting of hundreds, if not thousands, of services, serviced by many teams of engineers. The process of building and deploying maintainable services required a proper CI/CD setup, monitoring, and actionable alerting. This was echoed in my experiences when I transitioned over to writing lower-level networking code in Go on various networking teams. When you are writing code that is meant to be deployed to thousands of hypervisors or servers in various locations around the world—and when that code controls fundamentals’ ingress and egress networking—automation is key. This experience has continued at Fastly, a CDN provider with points of presence around the world.

Whether it is homegrown networking software or third-party OSS such as the BIRD routing daemon, I have learned that we absolutely need to be able to roll forward or roll back changes with ease. I am also a huge proponent of actionable alerts and runbooks; from experience, noisy alerts that are not directly tied to specific actions should never be pageable. I’ve also come to appreciate Go for what it offers when writing networking code; compared to languages such as C, it has been far easier to iterate code quickly and cross-compile applications for various platforms using Go. Go also has a useful network standard library and a growing ecosystem of packages that ease the process of writing code all the way from layer 2 and packet sockets to layer 7 using HTTP.

In summary, if I had to advise someone newly entering this field of networking and Go software engineering, I would say the following:

-   My ethos when writing software at any large company is to keep it simple. Write such easily readable, modular, extensible, and well-documented code so that a new engineer well versed in Go but unfamiliar with the company’s ecosystem would be able to easily join and contribute. I believe that excellent documentation and clear, simple code will always beat clever code.
-   When it comes to CI/CD and Infrastructure as Code, there are numerous options available that often depend on the use case. Will the software be run as a binary on a host machine? Can it be containerized? Are we building Debian packages? Whatever it is you use, make sure it is easy to both deploy and roll back the version of a service with ease.
-   Learn the idiosyncrasies of Go and have some agreed-upon best practices for company repositories.
-   Though I absolutely appreciate third-party packages in the Go networking ecosystem (`netaddr`, `gobgp`, and so on), I also like to read through code and confirm my understanding of its functionality. This also often allows us to find bugs and upstream contributions.
-   Make sure you have white-box monitoring and actionable alerts configured for your services.

And with these tips, I encourage everyone to embrace the Gopher life!

Bookmark

# Antonio Ojea

Antonio Ojea is a Software Engineer at Red Hat, where he works on Kubernetes and other open source projects, mainly focused on cloud technologies, networking, and containers. He is currently a maintainer and contributor on the Kubernetes and KIND projects and has contributed in the past to other projects such as OpenStack and MidoNet.

During my early years as a professional, I started in the network department of a telecommunications company. We were responsible for the internal network and its services (DNS, email, WWW, and so on). At that time, our automation consisted basically of the following:

-   **Configuration**: TCL/Expect scripts that connected to the network devices to apply different configurations
-   **Monitoring**: Perl scripts that polled via SNMP the network devices and stored the data on **Round Robin Database** (**RRD**) files
-   **Logging**: Using a central Syslog server dumping all logs to text files that were rotated periodically via `cron`
-   **Alerting and reporting**: Processing text files with Perl, `cat`, `grep`, `cut`, `awk`, `sed`, `sort`, and so on, and sending the result via email

If we look back, in hindsight, it’s incredible how much everything has improved and how interesting has been its evolution, especially in the open source area.

At the beginning of the 2000s, open source software was gathering momentum, the Apache license opened a new way for FOSS and corporations to interact, and there were already several stable Linux distributions providing the support, maintenance, security, and reliability required by enterprises.

During the 2000s, some projects started to flourish, improving the existing network automation. Some of them are still alive these days:

-   **Really Awesome New Cisco confIg Differ** (**RANCID**): Monitors the device configurations and uses a versioning backend such as CVS, Subversion, or Git to maintain a history of changes.
-   **Nagios**: It was kind of the industry standard for monitoring and alerting.
-   **Cacti**: A complete network graphing solution designed to harness the power of RRDTool’s data storage and graphing functionality.

However, it wasn’t until the late 2000s that open source entered the spotlight, regulations were more clear about free software licenses, and the open source ecosystem was more solid and stable. Companies started to use and contribute to open source, attracted by the growth and change potential and the economic benefits in contrast to the existing licensing model of private software.

During this period, and driven by the necessity of businesses and companies to be more agile, the infrastructure becomes more flexible: virtual machines, containers, software-defined networks, and so on. All these changes cause an evolution in the industry. It’s the dawn of the cloud, and network engineers start to have access to the networking data plane with technologies such as OpenFlow, or to the physical or virtual device configurations via APIs. The network becomes more open and programmable, creating unlimited opportunities for software developers.

My career was following this evolution. I started creating simple scripts and using other software projects to help me automate my work. However, once you realize you can build your own tools, collaborate with others to add the features that you need, and/or fix the limitations or bugs that are impacting you, you just can’t stop. That’s how I became a Kubernetes contributor and maintainer on SIG-Network. There is no secret: study, practice ... repeat.

Nowadays, and thanks to the explosion of open source projects and collaborative tools, it is easy to practice. Every project will be happy to have people willing to help, or you can just create your own project. There will always be someone that will be interested. The same is happening for studying; there is a lot of material accessible for everyone – videos, tutorials, and blogs – but I always recommend having some key books at hand, not just for reading, but also for consulting. Good books never age.

Remember, a programming language is just a tool. There is no ring to rule them all. There are tools you feel more comfortable with or are better suited for some kind of work or to solve some specific problem. Go is the core language for the container ecosystem; the main projects such as Kubernetes, Docker, and so on are built using Go. If you plan to work on network automation and containers, Go is definitively the appropriate language for you.

Bookmark

# Carl Montanari

_Carl defines himself as an ex(?) network person. He is a Python and Go developer, and creator of Scrapli(go), a Go package used in this book._

When I first started getting involved in the network automation community, the idea of anything but Python for network automation felt a bit insane. _Of course_, there were folks out there using things other than Python—maybe they had some Perl or Ruby, or maybe crazy folks had some C or something, but it really felt that Python was generally the _one ring to rule them all_. I leaned into Python, and, like many folks, I quickly fell in love. Python is a really neat language, and for somebody like me, without any kind of programming or computer science background, it served as an amazing and reasonably gentle introduction to the world of software.

For a good long while, I kind of felt like the network automation folks espousing Go were living in a fantasy land! Why would you need anything other than Python? Certainly, the speed/ease of development of Python outweighed the general speed of Go. Surely the much larger network automation ecosystem in Python was such a leg up that Go could never compete! Perhaps, I thought, the Go network automation advocates only had the newest fanciest gear that had 100% support for everything they could need to do with RESTCONF or gRPC. They probably also drank only the finest artisan coffees and beers and had enviable mustaches and/or colorful, fancy hair!

Naturally, these thoughts are all silly, and eventually, I started growing out a fancy mustache and learning Go. Just kidding—I can’t grow a mustache, or at least not an enviable one, but I did dive into Go!

Of course, I never had any delusion that Python was truly the _one ring to rule them all_, but learning one language was hard enough, so perhaps I was just protecting my sanity from trying to learn another one! It’s a bit unclear whether I’ve retained my sanity, but I do feel like I have learned quite a bit about Go over the past few years! For anyone that is on a journey like mine and looking to dig into Go, here are a few things I would recommend:

-   Lean into the typing ecosystem in Python. `mypy` is awesome—you will catch bugs you had no idea you had. You will learn a ton about typing, and the best part: if your typing is all broken, your programs will still run! Being a pretty rabid-type hinting fan, I feel it helped me a ton when going into Go where it is required.
-   Take the time to really understand interfaces and how to use them idiomatically. At first, for me, they were just kind of clunky abstract base classes, but of course, they really are more than that. While we’re at it, make sure to understand the empty interface and how to use and abuse that!
-   Stop trying to inherit all the things! This was (is?!) difficult for me—I quite fancied inheritance (perhaps too much, and perhaps that is a taboo nowadays anyway?), so it has been somewhat of a challenge at times to break away from that pattern. Sure, embed a struct here and there, but generally try to move away from that inheritance style mentality.
-   Let the robots (linters) yell at you and tell you how bad your code is! I like `golangci-lint`, which is a linter aggregator that runs tons of linters against your code. Get a ton of errors, and search-engine-engineer your way to understanding why the error exists and how you can do better. While annoying, I’ve learned a ton from all the errors I’ve created this way!

I suspect Go will continue to become more and more commonplace in the network automation community. The benefits of language—speed, small footprint, compiled binary, and on and on—are hard to ignore. Moreover, as the network automation ecosystem continues to expand and grow, I believe that network automation roles will be increasingly software-centric, rather than network-centric or automation/software as an afterthought of a network role; as that happens, Go will be increasingly important for all the reasons espoused in this very book! Of course, just as Python is not the _one ring to rule them all_, neither will Go be, but both are tools you should absolutely have in your toolbelt... or some other worn-out platitude. Happy Gophering!

Bookmark

# Brent Salisbury

_Brent is a Principle Software Engineer with over 20 years of networking and compute experience. He started in network ops and architecture and gradually transitioned into network software development. He is as bullish as ever on the future of the prospects for young engineers entering the networking industry._

We have witnessed trends in networking come and go, and projects succeed and fail during a few innovation cycle booms and busts in the still-young life of the internet. Through these important iterations, one paradigm shift that will stick is the adoption of DevOps practices in networking. A core component of DevOps is automation. To scale network automation, it is important to have tools that are powerful yet not overly complex to use for the operator. The authors have done an excellent job laying out reasons Go has arguably become the de facto language for infrastructure programming over the past few years as libraries have matured, and some of the largest open source projects have been written in Go.

Whether you are a network engineer or a seasoned developer, it is often said a particular language is just a tool and we shouldn’t grow too attached to one specific technology. While there is some truth in that premise, in the specific case of a language such as Go for networking, I would argue the right tool for the job is incredibly important. We are expecting a large swath of networking professionals to evolve into DevOps engineers for the network. If we are expecting a retooling of engineers’ skill sets, we should make that path as easy as possible. The learning curve, packaging, and baseline performance of Go all benchmark exceptionally well as compared to peer languages, making it an excellent choice for both a newcomer and a seasoned developer for programming and automation.

Here are some recommendations for those getting started in the network programming and automation journey:

-   Embrace open source.
-   Learn Linux and Linux networking.
-   Pick a language such as Go to start hacking.
-   Get familiar with open source automation tools such as Ansible and Jinja.
-   Learn how to use Git and its potential impact on configuration management.
-   Start with a read-only project that won’t do damage to the network as you are getting comfortable with automation and coding. Examples such as network monitoring/telemetry or configuration management/backups are relatively safe places to begin.
-   Programmatically improve the understanding of the state of your network. Stop driving using the rear-view mirror!
-   Learn about current developer tools and deployment mechanisms (Kubernetes, containers, popular libraries, and so on).
-   Explore how to create CI/CD pipelines for your networks.

Start thinking of your network configurations as code. Automated outages are increasingly at the root of some of the more recent high-profile outages. Leverage your experience in operations, and create tests and safeguards to prevent common mistakes someone doing automation without a background in networking would not be aware of. Network engineers are not endangered species; it takes years to understand how networks work and how to build them at scale. By combining a new discipline such as programming, it makes you that much more valuable in being able to connect the increasingly complex environments in today’s networks.

In closing, your goal should be to ensure the network is not a blocker of business velocity. Changes to the network taking weeks to implement must be a thing of the past. That is, of course, easier said than done, as network uptime is, and will always be, the number one metric a network team is going to be judged by. If I look at any projects, deployments, or products that I have done, the successful ones were where we took complexity and made it a little bit simpler. As networking professionals continue to evolve, powerful yet simple-to-use tools such as Go coupled with automation projects will be key enablers. Lastly, don’t be afraid to fail. Find your strengths and work around your weaknesses. The network is a big boat and hard to steer, but I firmly believe we are tacking in the right direction with automation.

Bookmark

# Maximilian Wilhelm

_Maximilian—Max—Wilhelm is a Holistic (Network) Automation Evangelist, trying to bring software engineering methods to network automation, and helping to overcome vendor lock-in._

_He developed a weakness for networking, IPv6, and routing early on and is an avid open source enthusiast, cofounder, maintainer, and contributor of Bio-Routing and ifupdown-ng, a regular speaker at open source and networking conferences, founder of the FrOSCon Network Track, and co-host of the virtualNOG.net meetings._

_He’s currently working as a Network Automation Engineer at Cloudflare and does a little moonlighting as a Senior Infrastructure Consultant. His second calling is being the lead architect behind the widely automated Freifunk Hochstift community network where he got his hands dirty with ifupdown2 as well as ifupdown-ng, VXLAN, Linux VRFs, BGP, and OSPF, plus infrastructure automation with Salt Stack, and has been afraid of commercial SDN solutions_ _ever since._

## A little bit of history

Coming from a Linux administrator/systems engineering background, I’ve been used to having home-grown automation solutions in place to manage a fleet of—for me at the time—a large number of servers and clients since my first job at the IT center of the Institute of Mathematics at Paderborn University in early 2004.

We had a locally developed software suite called SDeployment—written in Shell if I remember correctly—that was responsible for provisioning the correct software packages and desired configuration file state onto Linux-based servers and clients and enforcing the desired state to stay this way.

This even helped to detect an intruder who managed to exchange the `sshd` binary, which didn’t have support for Kerberos, so he needed to change the `sshd_config`, which got overwritten after 1 hour and the service didn’t start anymore.

At the time this was a huge benefit over solutions such as CFEngine, which could do incremental changes to configuration files but not maintain them holistically; Puppet had not been born yet (according to Wikipedia).

With the rise of Bcfg2, Puppet, Chef, Salt, and Ansible, we saw a shift from incremental configuration changes to intent-based configuration management in the wider industry, where the operator describes the desired state (intent) and writes templates to generate contents of entire configuration files, and the configuration management solution’s task is to make this a reality and keep it this way.

## Mental shift to holistic automation

The systems engineering/SRE world underwent this shift in thinking a long time ago, but it feels like the majority of network automation solutions are still following the idea of making incremental changes to the routers and switches out there, which, at the same time, might also be managed manually by operators typing (or copying) magic spells into a CLI.

This makes the device configuration the synchronization point, and we don’t really have an idea of what this configuration will look like in full without checking back on the device.

I believe we, as network (automation) engineers, need to follow suit, make the mental shift to the holistic approach, let Perl, Shell, and Expect scripts be, and bring software engineering methods to network automation. This way, we are able to tackle the problems at hand at an abstract level and build solutions that can be reasoned with, tested on their own, and that scale to our needs (see [_Chapter 5_](https://subscription.imaginedevops.io/book/cloud-and-networking/9781800560925/2B16971_05.xhtml#_idTextAnchor128), _Network Automation_).

For the most daunting problem of configuration management, this means plugging some of those systems together and building a solution that generates and owns the full device configuration.

The automation will likely rely on multiple inputs to gain full knowledge of the topology, operational overrides, subscribers, and services, as well as rules to derive the configuration from all of that.

This is following the overarching goal to do as few configuration changes as possible and leverage protocols such as BGP and BMP to extract/observe state or manipulate device state where more dynamic changes are required.

## This is the way

Having all of this in the cards, the only API you need from a device is a function to upload a new complete configuration and let the device figure out the path from the current configuration to the new one.

Dealing with diverging configuration parts across the fleet, carefully cleaning up old approaches to configure X, doing incremental changes, and figuring out how to interact with a platform API, a dialect of NETCONF, YANG, and so on would all be from the past—wouldn’t that be great?

I believe we have a bright future ahead of us!

That’s where this great and inspiring book and Go come in!

With Go, you have a very solid foundation to build reliable, scalable, and fairly easily testable and observable software. Prometheus integration is at your fingertips.

This way, you can build tools to monitor your network (via BMP or streaming telemetry, for example), inject routes via BGP, or build your own holistic network config generator and deployment pipeline, as outlined previously.

Existing open source suites such as Bio-Routing can help you on the first part (using BMP/RIS) and act as the foundation to, for example, build a route-injector following your business logic.

The fact that you are reading this indicates you are looking into building your own automation solution to tackle your organization’s needs—that’s great!

If you can, please share it as open source and present it at your local NOG—or VirtualNOG—so that others can benefit and learn from it too. Good luck!

Bookmark

# Matt Oswalt

_Matt is a Systems Engineer at Cloudflare, where he works on proxies and control plane systems. He blogs at https://oswalt.dev and occasionally posts on Twitter as @Mierdin._

I’m grateful to have been exposed to software development as well as infrastructure technologies such as networking at roughly the same time in my life. While I had toyed around with the BASIC-esque language on my TI-82 calculator in high school (okay, _toyed_ is a stretch—I created a rudimentary Galaga clone while failing Geometry) and taken a single semester of programming in Visual Basic, it wasn’t until university that I first encountered Linux, networking, and a modern programming environment.

Over the next few years, I bounced back and forth between what seemed to be fairly isolated technical domains. Doing so often made me feel like a beginner in everything and an expert in nothing. I’ve had more than a few moments of anxiety, worrying that I’m not doing the right things in my career. In retrospect, however, this was the best experience I could have asked for. It kept me uncomfortable, and in this state, I honed the skill that I prize above all others, and that’s my ability to learn. This skill has a snowball effect—having a formalized system of learning gives me the confidence to try new, more challenging things, which usually forces me to be even more rigorous and efficient in my learning process, and so on.

These days, there is a multitude of things to learn, and while it may be tempting to learn them all, we cannot. Something I’m still working on is my ability to seek out those skills that will really impact my career and the industry. In my experience, the kind of technologies and skills that have staying power are not always those that get the hype on social media or stars on GitHub—often, these are more fundamental technologies or ways of thinking that allow you to more quickly understand whatever the latest manifestation of those ideas might be.

If you’re new in your career, or if you feel like you might be stagnating a bit but you’re not sure where to go, hopefully the following advice is helpful to you:

-   Stay curious. The work of learning is never finished. Don’t get too focused on attaining certification _X_ or being able to add technology _Y_ to your resume—these are fleeting. Rather, take pride in building a continuously improving system of learning, and hone your own ability to acquire new skills efficiently.
-   So much of what we tend to cling on to in our lives and careers is a crippling distraction. Separate the essential few from the trivial many and focus on what will allow you to make your highest level of contribution. It’s far better to do a few things exceptionally well than to create a bounty of mediocre work.
-   There are many more highly skilled engineers building efficient, scalable systems that you will never hear about; then, there are people posting about technology _X_ on social media and getting _all the likes_. The vast majority of technology hot takes on social media aren’t worth the bits used to transmit them.
-   The technical skills that have the steepest learning curve can often (but do not always) have the biggest reward. Be very careful not to make career-limiting technical decisions based on how adoptable/approachable a technology may be; often, industry-changing innovations will not come with a perfect user experience at first, and the opportunities are much more plentiful for those who don’t wait for the polished user manual. At the same time, do not fall into the trap of believing that the more complex or difficult to learn, the better it must be. As with most things in life, the truth is probably somewhere in the middle.
-   No technology is a panacea; they were all designed with specific trade-offs in mind, including Go. If you haven’t found the trade-offs, you haven’t looked hard enough. Your job as an engineer is to understand these trade-offs and pick a technology that aligns best with the trade-offs you want to make in your current situation.

Happy learning!

Bookmark

# Further reading

-   _Decomposing Data_ _Structures_: https://gratuitous-arp.net/decomposing-complex-json-data-structures/
-   Ondatra: https://github.com/openconfig/ondatra
-   Feature profiles: [https://github.com/openconfig/featureprofiles](https://github.com/openconfig/featureprofiles)
-   FrOSCon Network Track: [https://myfirst.network](https://myfirst.network)